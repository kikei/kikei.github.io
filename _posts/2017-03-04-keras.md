---
layout: post
title:  "Keras の環境構築をした"
categories: ai
---

ArchLinux で Keras をやるための環境構築をしてみる。

当然、深層学習の学習のためである。
Keras を選んだ理由は、現時点でもっとも使い易いという評判を聞くからである。

Keras のバックエンドとしては TensorFlow を利用する。

TensorFlow は Docker で動かし、
NVIDIA の GPU を使い、CUDA に計算させるようにする。

細かい環境は次の通り。

OS:

```
% uname -a                                                          
Linux fg-arch 4.9.11-1-ARCH #1 SMP PREEMPT Sun Feb 19 13:45:52 UTC 2017 x86_64 GNU/Linux
```

GPU:

```
vv% lspci -v | grep GeForce -A3
02:00.0 VGA compatible controller: NVIDIA Corporation GP106 [GeForce GTX 1060 6GB] (rev a1) (prog-if 00 [VGA controller])
	Subsystem: ASUSTeK Computer Inc. Device 85c5
	Flags: bus master, fast devsel, latency 0, IRQ 42
	Memory at f6000000 (32-bit, non-prefetchable) [size=16M]
```

### GPU の確認

まずは、OS がグラフィックボードを認識しているか確認する。

次のコマンドで、見覚えのあるボードが表示されればOK。

```
% lspci | grep NVIDIA
02:00.0 VGA compatible controller: NVIDIA Corporation GP106 [GeForce GTX 1060 6GB] (rev a1)
02:00.1 Audio device: NVIDIA Corporation Device 10f1 (rev a1)
```

自分の環境でははじめ何も出なかったが、以下の経緯を踏んでうまくいった。

#### グラボの認識

まず、PCを開けてみたところ、グラボがハード的に起きていなそうに見えた。

とりあえず隣りの PCIe に挿し替えてみる作戦をとった。
電源投入すると、グラボのファンが回転し出し、小さい LED が発光した。
うまくいったようだ。

しかし、今度は画面が表示されなくなった。
起動時のメッセージが流れたあと、黒画面になり、何もできない。

#### ターミナルの表示

すこし試したところ、次のことがわかった。

- グラボの HDMI 出力に繋いで起動すると、起動画面は表示されるものの、
  その後、黒画面になってしまう。
- マザー内蔵の HDMI 出力に繋いで起動すると、はじめから画面に何もでない。

UEFI の設定で、映像の優先出力を On-board に替えてみた。
今回は、CUDA がしたいだけなので、出力自体はどうでもいい。

この状態で起動するとターミナルが表示されて、
さらに `lspci` で `NVIDIA` の存在が確認できた。

```
% lsmod | grep nvidia
nvidia_drm             49152  0
nvidia_modeset        794624  1 nvidia_drm
nvidia              12197888  1 nvidia_modeset
drm_kms_helper        126976  2 i915,nvidia_drm
drm                   294912  4 i915,nvidia_drm,drm_kms_helper
```

### `nvidia` モジュールのインストール

モジュールをインストールする。

まずは `pacman` でサクっと。

```
% pacman -Su cuda nvidia-libgl
% ls /opt/cuda
```

うまくできると、`/opt/cuda` がつくられている。

CuDNN も同ディレクトリにインストールしておく。

```
% wget http://developer.download.nvidia.com/compute/redist/cudnn/v5.1/cudnn-8.0-linux-x64-v5.1.tgz
% tar xvzf cudnn-8.0-linux-x64-v5.1.tgz
% sudo install cuda/include/* /opt/cuda/include/
% sudo install cuda/lib64/* /opt/cuda/lib64/
```

### `nvidia-smi` の起動

`nvidia-smi` とは、NVIDIA System Management Interface のことである。

NVIDIA GPU の状態を監視するためのインターフェースだそうだ。

次の手順で言われるままに実行する。

[NVIDIA/nvidia-docker: Build and run Docker containers leveraging NVIDIA GPUs](https://github.com/NVIDIA/nvidia-docker)

#### NVIDIA+Docker のプラグインのインストール

まずは、`nvidia-docker` と `nvidia-docker-plugin` をインストールする。

```
% wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker_1.0.1_amd64.tar.xz
sudo tar --strip-components=1 -C /usr/bin -xvf /tmp/nvidia-docker*.tar.xz && rm /tmp/nvidia-docker*.tar.xz
% ls /usr/bin/nvidia-docker*
/usr/bin/nvidia-docker	/usr/bin/nvidia-docker-plugin
```

`nvidia-docker-smi` の起動。

`nvidia-docker-plugin` の起動も必要なようだが、
`nohup` で実行しており、PC再起動のたびに手動で実行しないといけなそうで面倒くさい。

```
% sudo -b nohup nvidia-docker-plugin > /tmp/nvidia-docker.log
% nvidia-docker run --rm nvidia/cuda nvidia-smi
Sat Mar  4 14:26:21 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 378.13                 Driver Version: 378.13                    |
n|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 106...  Off  | 0000:02:00.0     Off |                  N/A |
| 12%   53C    P0    27W / 120W |      8MiB /  6072MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

上記のように GPU の状態が確認できたので、うまくいった模様。

### NVIDIA Docker の起動

```
% nvidia-docker run -it gcr.io/tensorflow/tensorflow:latest-gpu bash
root@2a37d230a7f5:/notebooks# ls
1_hello_tensorflow.ipynb  2_getting_started.ipynb  3_mnist_from_scratch.ipynb  BUILD  LICENSE
```

見ていないから知らないが、Jupyter用のドキュメントが
デフォルトで配置されているようだ。

### TensorFlow プログラムの実行

Docker コンテナに入った状態で、 Python 実行。

```
root@2a37d230a7f5:/notebooks# python
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:02:00.0
Total memory: 5.93GiB
Free memory: 5.86GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0)
>>> print(sess.run(hello))
Hello, TensorFlow!
```

動いた。

なんかもっとスピードアップできるよ!! としきりに言われている気がするけど、
とりあえず気にしない。

### Keras のインストール

やっと Keras のインストールまできた。

これは `pip` でいける。素晴らしい。

```
# root@2a37d230a7f5:/notebooks# pip install keras
```

続きはこれから。

### 参考情報

- [Keras](https://keras.io/ja/)
- [Installing TensorFlow](https://www.tensorflow.org/install/)
- [NVIDIA System Management Interface NVIDIA Developer](https://developer.nvidia.com/nvidia-system-management-interface)
- [CUDA GPUs | NVIDIA Developer](https://developer.nvidia.com/cuda-gpus)
